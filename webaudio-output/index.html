<!doctype html>
<html>

<head>
  <meta charset="utf-8" />
  <title>Peer connection as input to Web Audio</title>
  <script type="module" type="text/javascript">

    'use strict'

    import { StreamVisualizer } from './StreamVisualizer.js'

    const startButton = document.getElementById('startButton')
    const callButton = document.getElementById('callButton')
    const hangupButton = document.getElementById('hangupButton')
    callButton.disabled = true
    hangupButton.disabled = true

    // startButton
    // ------------------------------------------------------
    startButton.onclick = () => {
      startButton.disabled = true

      navigator.mediaDevices
        .getUserMedia({
          video: { frameRate: { ideal: 30, max: 60 }, width: { ideal: 1280 }, height: { ideal: 720 } },
          audio: { echoCancellation: true, noiseSuppression: true }
        })
        .then((stream) => {
          localVideo.srcObject = stream
          localStream = stream
          callButton.disabled = false
        })
        .catch((e) => alert(`getUserMedia() error: ${e.name}`))

    }

    // callButton
    // ------------------------------------------------------
    callButton.onclick = async () => {
      callButton.disabled = true
      hangupButton.disabled = false

      pc1 = new RTCPeerConnection()
      pc1.onicecandidate = ({ candidate }) => pc2.addIceCandidate(candidate)
      pc2 = new RTCPeerConnection()
      pc2.onicecandidate = ({ candidate }) => pc1.addIceCandidate(candidate)

      pc2.ontrack = ({ streams }) => {
        if (remoteVideo.srcObject !== streams[0]) {
          remoteVideo.srcObject = streams[0]
          const streamVisualizer = new StreamVisualizer(streams[0], canvas)
          streamVisualizer.start()
        }
      }

      localStream.getTracks().forEach(track => pc1.addTrack(track, localStream))

      try {
        const offer = await pc1.createOffer({
          offerToReceiveAudio: 1,
          offerToReceiveVideo: 1,
        })

        pc1.getSenders().forEach(sender => {
          if (sender.track.kind === "video") {
            const params = sender.getParameters()
            if (params.encodings.length > 0) {
              params.encodings[0].priority = "high" // 一部のブラウザ向け
              params.encodings[0].networkPriority = "high" // 最新の仕様向け
              // params.encodings[0].maxBitrate = 10000000 // ビットレート調整（必要なら）
            }
            sender.setParameters(params).catch(err => console.warn("setParameters failed:", err))
          }
        })

        await pc1.setLocalDescription(offer)
        await pc2.setRemoteDescription(offer)

        const answer = await pc2.createAnswer()
        await pc2.setLocalDescription(answer)
        await pc1.setRemoteDescription(answer)
      } catch (err) {
        console.error("WebRTC connection error:", err)
      }
    }

    // hangupButton
    // ------------------------------------------------------
    hangupButton.onclick = () => {
      console.log('Ending call')
      pc1.close()
      pc2.close()
      pc1 = null
      pc2 = null
      hangupButton.disabled = true
      callButton.disabled = false
    }

    const canvas = document.querySelector('canvas')

    const localVideo = document.getElementById('localVideo')
    const remoteVideo = document.getElementById('remoteVideo')

    let localStream
    let pc1
    let pc2
    const offerOptions = {
      offerToReceiveAudio: 1,
      offerToReceiveVideo: 1,
    }

  </script>
</head>

<body>
  <div id="container">
    <p>localVideo</p>
    <video id="localVideo" playsinline autoplay muted></video>
    <p>remoteVideo</p>
    <video id="remoteVideo" playsinline autoplay muted></video>
    <canvas></canvas>
    <div>
      <button id="startButton">Start</button>
      <button id="callButton">Call</button>
      <button id="hangupButton">Hang Up</button>
    </div>
  </div>
</body>

</html>